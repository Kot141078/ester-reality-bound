# Synthetic data and closed loops

When models train on model outputs, variance drops.
Tails shrink. “Weirdness” disappears.
The system converges toward a smooth, beige mean.

Reality is the source of fresh entropy:
- messy
- frictionful
- noisy (often signal, not error)

If we cut the cord to reality, we risk:
- model collapse
- brittle behavior
- detachment from the world
